<!DOCTYPE html>
<html><head lang="en"><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>nvBases</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta property="og:image" content="">
    <meta property="og:image:type" content="">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="630">
    <meta property="og:type" content="website">
    <meta property="og:url" content="">
    <meta property="og:title" content="Enhancing High-Fidelity Rendering: Cooperative Learning of Coefficient and Basis Decoding">
    <meta property="og:description" content="">

    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Enhancing High-Fidelity Rendering: Cooperative Learning of Coefficient and Basis Decoding">
    <meta name="twitter:description" content="">
    <meta name="twitter:image" content="">



    <!-- mirror: F0%9F%AA%9E&lt -->
    <link rel="icon" href="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text y=%22.9em%22 font-size=%2290%22&gt;%E2%9C%A8&lt;/text&gt;&lt;/svg&gt;">
    <link rel="stylesheet" href="css/bootstrap.min.css">
    <link rel="stylesheet" href="css/font-awesome.min.css">
    <link rel="stylesheet" href="css/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <script src="js/jquery.min.js"></script>
    <script src="js/bootstrap.min.js"></script>
    <script src="js/codemirror.min.js"></script>
    <script src="js/clipboard.min.js"></script>
    <script src="js/video_comparison.js"></script>
    <script src="js/app.js"></script>
</head>

<body>
    <div class="container" id="header" style="text-align: center; margin: auto;">
        <div class="row" id="title-row" style="max-width: 100%; margin: 0 auto; display: inline-block">
            <h2 class="col-md-12 text-center" id="title">
                Enhancing High-Fidelity Rendering: Cooperative Learning of Coefficient and Basis Decoding<br>
                <small>
           
                </small>
            </h2>
        </div>
        <div class="row" id="author-row" style="margin:0 auto;">
            <div class="col-md-12 text-center" style="display: table; margin:0 auto">
                <table class="author-table" id="author-table">
                    <tr>
                        <td>
                            <a style="text-decoration:none" href="">
                           Wenpeng Xing, Jie Chen, Xingxing Yang, Zaifeng Yang, Ka Chun Cheung, Simon See, and Yike Guo.
                            </a>
                            <br><br>
                        </td>
                    </tr>
                </table>
            </div>
        </div>
    </div>
    <script>
        document.getElementById('author-row').style.maxWidth = document.getElementById("title-row").clientWidth + 'px';
    </script>
    <div class="container" id="main">

        <div class="row">

            <div class="col-md-8 col-md-offset-2">
                <div class="video-compare-container" id="materialsDiv">
                    <video class="video" id="materials" loop playsinline autoPlay muted src="video/experiment_video/dense_view_training/tensorf_ours_merge.mp4" onplay="resizeAndPlay(this)"></video>
                    <canvas height=0 class="videoMerge" id="materialsMerge"></canvas>
                </div>
                <p class="text-justify">
                    Our results are shown on the left, and the results of TensoRF are shown on the right.
                </p>
			</div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
		Learning effective scene representation for novel view synthesis has been a long-standing research issue. In our work, we introduce a cooperative learning approach that jointly decodes coefficient and basis under varying illumination conditions. 
Our methodology approximates the scene's geometry and appearance features as tensorial radiance fields, enabling the estimation of per-point features. The key variables in our model are illumination and viewing directions, identified as the primary factors influencing rendering outcomes. Initially, per-point appearance features undergo feature-wise linear modulation (FiLM) to transform into \textit{factors}-variant coefficients. These coefficients are adept at spanning the manifolds of illumination and viewing directions as observed in the training images. Simultaneously, a linear layer is used to convert the appearance features into a factors-invariant neural basis.
Subsequently, these factors-variant coefficients and the factors-invariant neural basis are intricately blended using an MLP network, facilitating the production of high-fidelity rendering results.
Our experimental findings demonstrate that this method successfully learns a singular neural scene representation capable of rendering novel views under diverse illuminations encountered during training, thereby achieving state-of-the-art quality in rendering.
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Pipeline
                </h3>
                <image src="img/pipeline_12_12.png" class="img-responsive" alt="overview" width="80%" style="margin:auto;">
            </div>
        </div>




        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                
            </div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Results on Forward-facing Scenes
                </h3>
                <table width="100%">
                    <tr>
                        <td align="left" valign="top" width="50%">
                            <video id="v2" width="100%" playsinline loop muted controls>
                                <source src="video/experiment_video/forwardfacing/ours_fern_video.mp4" type="video/mp4" />
                            </video>
                        </td>
                        <td align="left" valign="top" width="50%">
                            <video id="v3" width="100%" playsinline loop muted controls>
                                <source src="video/experiment_video/forwardfacing/ours_flowers_video.mp4" type="video/mp4" />
                            </video>
                        </td>
                    </tr>
                    <tr>
                        <td align="left" valign="top" width="50%">
                            <video id="v2" width="100%" playsinline loop muted controls>
                                <source src="video/experiment_video/forwardfacing/ours_horns_video.mp4" type="video/mp4" />
                            </video>
                        </td>
                        <td align="left" valign="top" width="50%">
                            <video id="v3" width="100%" playsinline loop muted controls>
                                <source src="video/experiment_video/forwardfacing/ours_room_video.mp4" type="video/mp4" />
                            </video>
                        </td>
                    </tr>
                    <tr>
                        <td align="left" valign="top" width="50%">
                            <video id="v2" width="100%" playsinline loop muted controls>
                                <source src="video/experiment_video/forwardfacing/ours_trex_video.mp4" type="video/mp4" />
                            </video>
                        </td>
                        <td align="left" valign="top" width="50%">
                            <video id="v3" width="100%" playsinline loop muted controls>
                                <source src="video/experiment_video/forwardfacing/orchids_ours_video.mp4" type="video/mp4" />
                            </video>
                        </td>
                    </tr>
                </table>
			</div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Results on NeRF-synthetic Dataset
                </h3>
                <table width="100%">
                    <tr>
                        <td align="left" valign="top" width="50%">
                            <video id="v2" width="100%" playsinline loop muted controls>
                                <source src="video/experiment_video/nerf_synthetic/ours_chair_video.mp4" type="video/mp4" />
                            </video>
                        </td>
                        <td align="left" valign="top" width="50%">
                            <video id="v3" width="100%" playsinline loop muted controls>
                                <source src="video/experiment_video/nerf_synthetic/ours_drums_video.mp4" type="video/mp4" />
                            </video>
                        </td>
                    </tr>
                    <tr>
                        <td align="left" valign="top" width="50%">
                            <video id="v2" width="100%" playsinline loop muted controls>
                                <source src="video/experiment_video/nerf_synthetic/ours_hotdog_video.mp4" type="video/mp4" />
                            </video>
                        </td>
                        <td align="left" valign="top" width="50%">
                            <video id="v3" width="100%" playsinline loop muted controls>
                                <source src="video/experiment_video/nerf_synthetic/ours_lego_video.mp4" type="video/mp4" />
                            </video>
                        </td>
                    </tr>
                    <tr>
                        <td align="left" valign="top" width="50%">
                            <video id="v2" width="100%" playsinline loop muted controls>
                                <source src="video/experiment_video/nerf_synthetic/ours_materials_video.mp4" type="video/mp4" />
                            </video>
                        </td>
                        <td align="left" valign="top" width="50%">
                            <video id="v3" width="100%" playsinline loop muted controls>
                                <source src="video/experiment_video/nerf_synthetic/ours_ship_video.mp4" type="video/mp4" />
                            </video>
                        </td>
                    </tr>
                    <tr>
                        <td align="left" valign="top" width="50%">
                            <video id="v2" width="100%" playsinline loop muted controls>
                                <source src="video/experiment_video/nerf_synthetic/ours_mic_video.mp4" type="video/mp4" />
                            </video>
                        </td>
                        <td align="left" valign="top" width="50%">
                            <video id="v3" width="100%" playsinline loop muted controls>
                                <source src="video/experiment_video/nerf_synthetic/ours_ficus_video.mp4" type="video/mp4" />
                            </video>
                        </td>
                    </tr>
                </table>
			</div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Results on NeRF-synthetic Dataset with dense view training.
                </h3>
                <table width="100%">
                    <tr>
                        <td align="left" valign="top" width="50%">
                            <video id="v2" width="100%" playsinline loop muted controls>
                                <source src="video/experiment_video/dense_view_training/drums_300_ours_video.mp4" type="video/mp4" />
                            </video>
                        </td>
                        <td align="left" valign="top" width="50%">
                            <video id="v3" width="100%" playsinline loop muted controls>
                                <source src="video/experiment_video/dense_view_training/materials_300_ours_video.mp4" type="video/mp4" />
                            </video>
                        </td>
                    </tr>
                </table>
			</div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Results of trianing a single model with various illuminations.
                </h3>
                <div style="width: 30%;text-align: justify;display:inline-block;">
                    <video class="video" id="musclecar"  controls loop playsinline muted src="video/experiment_video/materials_multiple_illumination/ours/city_video.mp4" onplay="resizeAndPlay(this)"></video>
                </div>
                <div  style="width: 30%;text-align: justify;display:inline-block; ">
                    <video class="video" id="musclecar"  controls loop playsinline muted src="video/experiment_video/materials_multiple_illumination/ours/courtyard_video.mp4" onplay="resizeAndPlay(this)"></video>
                </div>
                <div  style="width: 30%;text-align: justify;display:inline-block;">
                    <video class="video" id="musclecar"  controls loop playsinline muted src="video/experiment_video/materials_multiple_illumination/ours/forest_video.mp4" onplay="resizeAndPlay(this)"></video>
                </div>
                <div  style="width: 30%;text-align: justify;display:inline-block;">
                    <video class="video" id="musclecar"  controls loop playsinline muted src="video/experiment_video/materials_multiple_illumination/ours/interior_video.mp4" onplay="resizeAndPlay(this)"></video>
                </div>
                <div  style="width: 30%;text-align: justify;display:inline-block;">
                    <video class="video" id="musclecar"  controls loop playsinline muted src="video/experiment_video/materials_multiple_illumination/ours/night_video.mp4" onplay="resizeAndPlay(this)"></video>
                </div>
                <div  style="width: 30%;text-align: justify;display:inline-block;">
                    <video class="video" id="musclecar"  controls loop playsinline muted src="video/experiment_video/materials_multiple_illumination/ours/sunrise_video.mp4" onplay="resizeAndPlay(this)"></video>
                </div>
                <div  style="width: 30%;text-align: justify;display:inline-block;">
                    <video class="video" id="musclecar"  controls loop playsinline muted src="video/experiment_video/materials_multiple_illumination/ours/sunset_video.mp4" onplay="resizeAndPlay(this)"></video>
                </div>
			</div>
        </div>
		
        <div class="row">

            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Results of relighting by interpolating illumination codes.
                </h3>
                <div class="video-compare-container" id="materials">
                    <video id="v2" width="100%" loop muted controls>
                        <source src="video/experiment_video/video_all.mp4" type="video/mp4" />
                    </video>
                </div>
            </div>
        </div>

            


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                The website template was borrowed from <a href="https://dorverbin.github.io/refnerf/">Dor verbin</a>.
                </p>
            </div>
        </div>
    </div>


</body></html>
